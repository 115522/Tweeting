{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">  <B> Tweets Clustering</B>  $~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$<B> BY INES REBHI</B>\n",
    " </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"images/giphy.gif\" width=\"400\" height=\"400\" align=\"center\"/>'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:blue;\"> <B>Introduction</B>\n",
    " </B> </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Data redundancy is an important problem of Twitter. Twitter users are likely to generate similar tweets (e.g., using the Retweet function) about some popular topics/events.\n",
    "a result of a huge number of tweets which let  tweetos not interested to loss time about reading for the same topic many tweets     \n",
    "  So by clustering similar tweets together, we can generate a more concise and organized representation of the raw tweets, which will be very useful for busy Tweetos to read only one tweet per class  </B> </br>\n",
    "\n",
    "<B> Aim of our Project is to  </B>\n",
    "<li> <B>1/ gathering real time tweets  using a twitter API </B></li>\n",
    "<li><B> 2/ Preprocessing tweets </B> </li>\n",
    "<li><B> 3/Apply a NLP to text tweets</B> </li>\n",
    "<li><B> 4/ Modeling By using K-means as a ML algorithm of clustering </B></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:blue;\"> <B>Keywords </B></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Text mining  $~~~/~~~~$clustering$~~~/~~~~$NLP $~~~/~~~~$tweepy$~~~/~~~~$ NLTK$~~~/~~~~$ twitter API </B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:blue;\"> <B>STEP1: Getting API keys from Twitter</B>\n",
    " </B> </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>An API is standing for Application Programming Interfaces (APIs) and they allow you to access resources only available on the server</B></br>\n",
    "<B>Now The Twitter API lets you read and write Twitter data. Thus, you can use it to compose tweets, read profiles, and access your followers‚Äô data and a high volume of tweets on particular subjects in specific locations.</B></br>\n",
    "<B>So how can I get an API from twitter developer ??? </B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<B style=\"color:orangered;\">1/ Create  twitter account </B>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/accounttwitter.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B style=\"color:orangered;\">2/Try this link to see how apply for a twitter api </B> </br></br>\n",
    "\n",
    "<B>https://www.youtube.com/watch?v=vlvtqp44xoQ </B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B style=\"color:orangered;\">3/ Create a project in twitter developer</B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Capture.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B style=\"color:orangered;\">3/Get API  Keys </B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/api.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B style=\"color:orangered;\"> 3/ Install Tweepy </B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Tweepy is an open source Python package that gives you a very convenient way to access the Twitter API with Python. Tweepy includes a set of classes and methods that represent Twitter‚Äôs models and API endpoints, and it transparently handles various implementation details, such as:</B>\n",
    "\n",
    "<B>* Rate limits</B>\n",
    "    \n",
    "<B>* Streams</B>\n",
    "\n",
    "<B> * Data encoding and decoding</B>\n",
    "    \n",
    "<B> * HTTP requests</B>\n",
    "    \n",
    "<B>* Results pagination</B>\n",
    "    \n",
    "<B>* OAuth authentication</B>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B style=\"color:orangered;\">4/ import Libraries  and credentials in our project </B> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy           # To consume Twitter's API\n",
    "import pandas as pd     # To handle data\n",
    "import numpy as np      # For number computing\n",
    "\n",
    "# For plotting and visualization:\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Twitter App access keys for @user \n",
    "#credential part\n",
    "\n",
    "# Consume:\n",
    "CONSUMER_KEY    = 'pUruES5UQBACkbkcOolgfmjop'\n",
    "CONSUMER_SECRET = 'H0zY8T19bQIAMGKxTNEVZV4T52QNMfruGu8FLbECmizbw7qr7l'\n",
    "\n",
    "# Access:\n",
    "ACCESS_TOKEN  = '1324988873538228224-Sbn1EJXcxKeItAV33UzO7wX7TsFYjA'\n",
    "ACCESS_SECRET = 'MMyMliA8oNgEYspY3mKQ4Wi73F4YsD9CiELkyChQpxebo'\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN,ACCESS_SECRET)\n",
    "api=  tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><B style=\"color:blue;\">STEP2: Gathring DATA  </B> </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B style=\"color:orangered;\">1/ Live streaming tweets\n",
    "  </B> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>In this Part we need to stream 10 000 tweets in real-time  from\n",
    "Twitter to solve the task of tweets clustering </B> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Danger:</b> <B>Please don't run this cell because it can make you a lot of time to do the streaming ! </B> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "import time\n",
    " \n",
    "class listener(StreamListener):\n",
    "    def on_data(self,data):\n",
    "       \n",
    "            saveFile = open('live_tweets.json','a')\n",
    "            saveFile.write(data)\n",
    "            saveFile.write('\\n')\n",
    "            saveFile.close()\n",
    "            return True\n",
    "       \n",
    "            time.sleep(5)\n",
    "    def on_status(self, status):\n",
    "        try:\n",
    "            if hasattr(status, 'retweeted_status') and hasattr(status.retweeted_status, 'extended_tweet'):\n",
    "                print('retweeted: ' + status.retweeted_status.extended_tweet['full_text'])\n",
    "            if hasattr(status, 'extended_tweet'):\n",
    "                print('extended_tweet: ' + status.extended_tweet['full_text'])\n",
    "            else:\n",
    "                print('text: ' + status.text)\n",
    "        except AttributeError:\n",
    "            print('attribute error: ' + status.text)\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN,ACCESS_SECRET)\n",
    "twitterStream = Stream(auth,listener(),tweet_mode='extended')\n",
    "\n",
    "twitterStream.filter(languages=[\"en\"],track=[\"politic\" , \"health\" , \"sport\",\"business\",\"entertaiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><B style=\"color:blue;\">STEP3:DATA PREPARATION </B> </h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><h3><B style=\"color:orangered;\">Data Processing and Wrangling  </B> </h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">><B style=\"color:green;\"> 1/ From json to csv </B> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>the csv form  serve to make our dataset(tweets) more visualised than json form. So we need to change our dataset from json to csv </B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"info info-block alert-info\">\n",
    "<b>INFO:</b> <B>It's unused to run these two cells </B> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json ('tweetsstreamed.json',lines = True)\n",
    "export_csv = df.to_csv ('bdtweets.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json ('live_tweets.json',lines = True)\n",
    "export_csv = df.to_csv ('bdtweets2.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">><B style=\"color:green;\"> 2/Cleaning text </B> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">><B>In this step we will \n",
    "<B><li>transform tweet text into lowercase</li></B>\n",
    "<B><li>remove twitter handles</li></B>\n",
    "<B><li>remove hyperlinks</li></B>\n",
    "    <B><li>remove non-alphanumeric characters such as punctuation marks </li></B>\n",
    "<B><li>remove whitespace</li></B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>a/keep only the text column and ignore the rest of features</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of tweets dataframe with duplicated tweets (20422, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@WTAJnews Great!  Another going out of busines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@DailyCaller @LisaMarieBoothe Health and educa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @MatthewJshow: @realDonaldTrump China is we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Video: Demba Ba sees red as he stands up for h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @texman71: Fuck your restrictions!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @WTAJnews Great!  Another going out of busines...\n",
       "1  @DailyCaller @LisaMarieBoothe Health and educa...\n",
       "2  RT @MatthewJshow: @realDonaldTrump China is we...\n",
       "3  Video: Demba Ba sees red as he stands up for h...\n",
       "4             RT @texman71: Fuck your restrictions!!"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "tweets = pd.read_csv(\"bdtweets2.csv\", usecols = ['text'])\n",
    "print(\"shape of tweets dataframe with duplicated tweets\",tweets.shape)\n",
    "tweets.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20417</th>\n",
       "      <td>TAKE ACTION AND OPPOSE RUSHED APPROVALS WITHOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20418</th>\n",
       "      <td>Revive your aging skin and reduce the appearan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20419</th>\n",
       "      <td>Busy üêù!!!! \\n\\nWhen you own a business this is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20420</th>\n",
       "      <td>RT @JeaneF1MSP: Dear @BBCScotNine, unpaid care...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20421</th>\n",
       "      <td>RT @hycfreedom: @HBO @HackedOffHugh HUNTER BID...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "20417  TAKE ACTION AND OPPOSE RUSHED APPROVALS WITHOU...\n",
       "20418  Revive your aging skin and reduce the appearan...\n",
       "20419  Busy üêù!!!! \\n\\nWhen you own a business this is...\n",
       "20420  RT @JeaneF1MSP: Dear @BBCScotNine, unpaid care...\n",
       "20421  RT @hycfreedom: @HBO @HackedOffHugh HUNTER BID..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RT @SenTomCotton: This opinion reads like the delusional ramblings of a Resistance lawyer afflicted with Trump Derangement Syndrome. Judge‚Ä¶         186\n",
       "RT @btsportfootball: Nothing but respect ‚ù§Ô∏è\\n\\nMessi ü§ù Ronaldo\\n\\nüì∫ BT Sport ESPN HD https://t.co/Qo1KUQKZ7Q                                        171\n",
       "RT @SteveGuest: Joe Biden defeated AGAIN by the Teleprompter.\\n\\n\"For Secretary of Health and Education Services, I nominate Xavier Bacheria.‚Ä¶      153\n",
       "RT @MelissaReddy_: Demba Ba üëèüèΩ\\nIstanbul Basaksehir üëèüèΩ\\nPSG üëèüèΩ\\n\\nShowing us 'zero tolerance' is more than just empty words, can be easily acti‚Ä¶    137\n",
       "RT @SchmittNYC: Biden didn‚Äôt nominate Becerra - his handlers did                                                                                    120\n",
       "                                                                                                                                                   ... \n",
       "@RideWithA_Lexis bitch get ayden telling all your business üòÇüò≠üôÑ                                                                                        1\n",
       "@rlupinss WHAT THE FUCK ITS GENUINELY NO ONES BUSINESS WTFFFF                                                                                         1\n",
       "@JamesrossrJames @Clyde2241 Cancel vaccine - tRUmp malicious negligence\\n\\nVaccine redirected - Pfizer business decis‚Ä¶ https://t.co/sSx3JbiIQg        1\n",
       "@MaybellRomero @knitsandflowers In San Diego County, my alert today said: \"New public health stay at home order in‚Ä¶ https://t.co/tV7ea6ENUK           1\n",
       "@AnnelieseDodds Covid 19 Health Statistics: Corona Virus\\n2020 Health Article https://t.co/057O8QyW75                                                 1\n",
       "Name: text, Length: 13937, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['text'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><B>we are looking in our dataset and  note that we have many duplications that we must removing</B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>b/Remove duplicated tweets </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of tweets dataframe After removing duplicated tweets (13937, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tweets.drop_duplicates(subset='text',inplace=True)\n",
    "# tweets.drop_duplicates(subset=['text'], keep='first', inplace=True)  #tou can also run this line of code to drop duplicate tweets\n",
    "\n",
    "print(\"shape of tweets dataframe After removing duplicated tweets\",tweets.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><B> we can showing top of hashtag in our dataset </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "tweets['hashtags'] = tweets['text'].apply(lambda twt : re.findall(r\"#(\\w+)\", twt))\n",
    "d = Counter(tweets.hashtags.sum())\n",
    "# print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3602"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_hashtags = pd.DataFrame([d]).T\n",
    "tweets_hashtags.columns = ['freq']\n",
    "tweets_hashtags.freq.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top hashtag in our dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COVID19</th>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assignment</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homework</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nursing</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>research</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Literature</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Essay</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chemistry</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            freq\n",
       "COVID19      103\n",
       "business      81\n",
       "health        42\n",
       "assignment    38\n",
       "homework      33\n",
       "Nursing       31\n",
       "research      31\n",
       "Literature    29\n",
       "Essay         28\n",
       "chemistry     26"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_hashtags.sort_values(by=['freq'], ascending=False, inplace=True)\n",
    "print(\"top hashtag in our dataset\")\n",
    "tweets_hashtags.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among 20000 Tweets, 3602 Hashtags were used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Top 10 Hashtags of dataset')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Visualization of Top 10 Hashtags\n",
    "labels = tweets_hashtags.head(10).index.values.tolist()\n",
    "freq = tweets_hashtags['freq'].head(10).values.tolist()\n",
    "index = np.arange(len(freq))\n",
    "\n",
    "print(\"Among 20000 Tweets, 3602 Hashtags were used.\")\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.bar(index, freq, alpha=0.8, color= 'orangered')\n",
    "plt.xlabel('Hashtags', fontsize=13)\n",
    "plt.ylabel('Frequency', fontsize=13)\n",
    "plt.xticks(index, labels, fontsize=11, rotation=90, fontweight=\"bold\") \n",
    "plt.title('Top 10 Hashtags of dataset', fontsize=12, fontweight=\"bold\",color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.drop(['hashtags'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <B> c/extract the username through the tweets (preceded by @ or by RT @), emojis,punctuation</B></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great  another going out of business sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>health and education services is what he wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>china is well entrenched throughout business...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video demba ba sees red as he stands up for hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fuck your restrictions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20416</th>\n",
       "      <td>we haveright to education and good health we w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20417</th>\n",
       "      <td>take action and oppose rushed approvals withou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20418</th>\n",
       "      <td>revive your aging skin and reduce the appearan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20419</th>\n",
       "      <td>busy  when you ownbusiness this is really the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20421</th>\n",
       "      <td>hunter biden lied tony bobulinski  the form...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13937 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0              great  another going out of business sale\n",
       "1        health and education services is what he wan...\n",
       "2        china is well entrenched throughout business...\n",
       "3      video demba ba sees red as he stands up for hi...\n",
       "4                                 fuck your restrictions\n",
       "...                                                  ...\n",
       "20416  we haveright to education and good health we w...\n",
       "20417  take action and oppose rushed approvals withou...\n",
       "20418  revive your aging skin and reduce the appearan...\n",
       "20419  busy  when you ownbusiness this is really the ...\n",
       "20421     hunter biden lied tony bobulinski  the form...\n",
       "\n",
       "[13937 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "#clean text\n",
    "\n",
    "def CleanText(TextToClean):\n",
    "    TextToClean.lower()  #Normalization\n",
    "    TextToClean = re.sub(r'@[A-Za-z0-9]+', '',str(TextToClean)) #to extract @\n",
    "    TextToClean= re.sub(r':','',str(TextToClean)) #to remove :\n",
    "    TextToClean= re.sub(r'\\n','',str(TextToClean)) #to remove  \\n\n",
    "    TextToClean= re.sub(r'#','',str(TextToClean)) #to remove #\n",
    "    TextToClean= re.sub(r'!','',str(TextToClean)) #to remove #\n",
    "    TextToClean = re.sub(r'RT[\\s]','',str(TextToClean)) #to remove #\n",
    "    TextToClean = re.sub(r'https','',str(TextToClean)) #to remove hyper links\n",
    "    TextToClean = re.sub(r'_','',str(TextToClean)) #to remove hyper links\n",
    "    TextToClean = re.sub(r'~~~@‚Ä¶','',str(TextToClean)) #to remove blanc space\n",
    "    TextToClean =re.sub(r\"\\&\\S*\\s\", \"\", str(TextToClean))\n",
    "    TextToClean = re.sub(r\"\\&\", \"\", str(TextToClean))\n",
    "    TextToClean= re.sub(r\"\\+\", \"\", str(TextToClean))\n",
    "    TextToClean = re.sub(r\"\\#\", \"\", str(TextToClean))\n",
    "    TextToClean = re.sub(r\"\\$\", \"\", str(TextToClean))\n",
    "    TextToClean = re.sub(r\"\\¬£\", \"\", str(TextToClean))\n",
    "    TextToClean = re.sub(r\"\\%\", \"\", str(TextToClean))\n",
    "    TextToClean= re.sub(r\"\\:\", \"\", str(TextToClean))\n",
    "    TextToClean = re.sub(r\"\\@\", \"\", str(TextToClean))\n",
    "    TextToClean = re.sub(r\"\\-\", \"\", str(TextToClean))\n",
    "    TextToClean = re.sub(r\",\", \"\", str(TextToClean))\n",
    "    TextToClean = re.sub(r\" \\' \", \"\", str(TextToClean))\n",
    "    TextToClean = re.sub(r\"\\n \", \"\", str(TextToClean))\n",
    "    TextToClean = re.sub(r'\\s+[a-zA-Z]\\s+', \"\", str(TextToClean))\n",
    "    TextToClean = re.sub(r\" \\? \", \"\", str(TextToClean))\n",
    "    TextToClean = re.sub(r'[^\\w\\s]','',str(TextToClean))\n",
    "    \n",
    "#     TextToClean = re.sub(r'\\s+', \"\", str(TextToClean))#Removing Extra Whitespaces\n",
    "#     TextToClean = re.sub(r'\\s+[a-zA-Z]\\s+', \"\", str(TextToClean))#Removing single carecter\n",
    "\n",
    "\n",
    "    return TextToClean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def remove_emoji(Text_with_emoji):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (appel phone)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', Text_with_emoji)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tweets['text'] = tweets['text'].apply(CleanText)\n",
    "tweets['text'] = tweets['text'].apply(remove_emoji)\n",
    "# tweets['extended_tweet'] = tweets['text'].apply(CleanText)\n",
    "# tweets['extended_tweet'] = tweets['text'].apply(remove_emoji)\n",
    "#lower text\n",
    "tweets[\"text\"] = tweets[\"text\"].str.lower()\n",
    "# tweets[\"extended_tweet\"] = tweets[\"text\"].str.lower()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' new scathing analysis of s shady business by the  thereslot of questions around this guy the'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['text'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b></b> <B> Now ! we have only cleaned and lower text </B>  \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:blue;\"> <B>  Natural Language Processing </B>  </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Natural language processing includes many different techniques for interpreting human language, ranging from statistical and machine learning methods to rules-based and algorithmic approaches.</B>\n",
    "</br>\n",
    "<B>Basic NLP tasks include tokenization and parsing, lemmatization/stemming, part-of-speech tagging, language detection and identification of semantic relationships.</B></br>\n",
    "<B>In general terms, NLP tasks break down language into shorter, elemental pieces, try to understand relationships between the pieces and explore how the pieces work together to create meaning.</B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 style=\"color:orangered;\"> <B> Natural Language Toolkit (NLTK) for  analyzing text </B>  </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>NLTK is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language</B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><h4 style=\"color:green;\"><B> Install NLTK </B></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.5.zip (1.4 MB)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: regex in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (2020.6.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (4.47.0)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py): started\n",
      "  Building wheel for nltk (setup.py): finished with status 'done'\n",
      "  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434679 sha256=3bc961ddc00caade782f8044f76ddea6f35277e2fc0e79d914c76b880c08c97e\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\ff\\d5\\7b\\f1fb4e1e1603b2f01c2424dd60fbcc50c12ef918bafc44b155\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.5\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><h4 style=\"color:green;\"><B> Install Conda package for NLTK </B></h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"images/anacondaNLTK.PNG\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><h4 style=\"color:green;\"><B>Install punkt</B></h4>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/punketinstalled.PNG\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "><h4 style=\"color:orangered;\"><B> remove stopwords </B></h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<B>In every language, some words are particularly common. While their use in the language is crucial, they don‚Äôt usually convey a particular meaning, especially if taken out of context. This is the case of articles, conjunctions, some adverbs, etc. which are commonly called stop-words.</br>\n",
    "Stop-word removal is one important step that should be considered during the pre-processing stages. </br>\n",
    "NLTK provides a simple list for English stop-words. </B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/stopwords.PNG\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><h4 style=\"color:green;\"><B> Tokenization </B></h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>In this step , we will split tweets text into token (words) by using NLTK‚Äôs TweetTokenizer.It can  ‚Äúcollapse‚Äù repeated characters - that is, lolll, lollllll, and lollllllllllll will all collapse to the same representation \"lolll\" (three ‚Äúl‚Äùs). This is helpful because we tend to think that these tokens represent approximately the same thing. This feature helps curb the curse of dimensionality (i.e. too many low-frequency tokens), while maintaining Twitter-specific features.  </B>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"she's\", 'off', \"you'd\", 'under', 'me', 'too', \"haven't\", 'retweet', 'only', \"needn't\", 'so', 'very', 'is', 'she', 'where', 'then', 'and', 'against', 'being', 'few', \"mustn't\", 'each', 'did', 'nor', 'what', \"wouldn't\", 'd', 'who', 'needn', 'such', 'couldn', 'mustn', 'to', 'some', 'of', 'just', 'his', 'her', 'having', 'but', 'which', 'on', 'aren', 'itself', 'has', 'after', 'ma', 'rt', 'i', 'there', 'any', \"didn't\", 'rts', 'am', 'both', 'didn', 'doesn', 'the', 'won', \"couldn't\", 'themselves', 'about', 'doing', 'out', 've', 'no', 'these', 'are', 'all', 'haven', 'was', \"you'll\", 'their', 'be', 'were', 'now', 'hers', 'theirs', 'hasn', 'hadn', 'own', 'does', 'him', 'down', 'into', \"it's\", 'them', \"hasn't\", 'm', 'other', \"won't\", 'shan', 'if', \"you've\", 't', 'weren', 'through', \"isn't\", 'wouldn', \"shouldn't\", 'below', 'yourselves', 'wasn', 'mightn', 'himself', 'it', 'during', \"shan't\", 'my', 'myself', 'over', 'we', \"aren't\", 'as', 'this', 'll', 'a', 'its', 'ain', \"mightn't\", 'before', 'should', 's', 'have', 'yourself', 'here', 'up', 'until', \"don't\", 'ourselves', 'whom', 'further', 'yours', 'will', 'those', 'not', 'been', 're', 'do', 'with', 'at', 'that', \"hadn't\", 'above', 'most', 'while', 'for', 'than', 'when', 'more', 'from', 'they', 'because', 'herself', 'why', 'same', \"weren't\", 'how', 'in', 'or', 'had', 'shouldn', 'our', \"doesn't\", 'again', 'by', 'an', \"you're\", 'don', 'y', 'you', 'isn', 'ours', 'he', \"should've\", 'once', \"wasn't\", \"that'll\", 'between', 'o', 'can', 'your'}\n"
     ]
    }
   ],
   "source": [
    "#*************************************************************************************************\n",
    "                                               #This is the stopwords\n",
    "#*************************************************************************************************\n",
    "\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "additional  = ['rt','rts','retweet']\n",
    "swords = set().union(stopwords.words('english'),additional)\n",
    "print(swords)\n",
    "\n",
    "tweets['text'] = tweets['text'].apply(lambda x: ' '.join([i for i in x.split() if  i not in (swords)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new scathing analysis shady business thereslot questions around guy'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['text'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*************************************************************************************************\n",
    "                                               #This is the tokenizer\n",
    "#*************************************************************************************************\n",
    "\n",
    "\n",
    "import nltk\n",
    "# nltk.download()\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "tweets['tokonized_text'] = '' \n",
    "\n",
    "tokenizer = TweetTokenizer()\n",
    "tweets['tokonized_text']  =tweets['text'].apply(tokenizer.tokenize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new',\n",
       " 'scathing',\n",
       " 'analysis',\n",
       " 'shady',\n",
       " 'business',\n",
       " 'thereslot',\n",
       " 'questions',\n",
       " 'around',\n",
       " 'guy']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['tokonized_text'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><h4 style=\"color:green;\"><B> Stemming </B></h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Stemming is the process of reducing inflection in words to their root forms such as mapping a group of words to the same stem even if the stem itself is not a valid word in the Language.</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "tweets['stemmed'] = tweets['tokonized_text'].apply(lambda x: [ps.stem(i) for i in x if i != ''])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new',\n",
       " 'scath',\n",
       " 'analysi',\n",
       " 'shadi',\n",
       " 'busi',\n",
       " 'thereslot',\n",
       " 'question',\n",
       " 'around',\n",
       " 'guy']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['stemmed'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><h4 style=\"color:green;\"><B> Lemmatization  </B></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# nltk.download('wordnet') #download wordnet package with code \n",
    "lmtzr = WordNetLemmatizer()\n",
    "tweets['lemma'] = tweets['stemmed'].apply(lambda x: [lmtzr.lemmatize(word,'v') for word in x if word!= ''])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new',\n",
       " 'scath',\n",
       " 'analysi',\n",
       " 'shadi',\n",
       " 'busi',\n",
       " 'thereslot',\n",
       " 'question',\n",
       " 'around',\n",
       " 'guy']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['lemma'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:blue;\"> <B> STEP4 : Modeling </B>  </h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><h4 style=\"color:green;\"><B> K-means </B></h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Now as a Ml Algorithm for clustering we will use K-means with cosine as a distance metric </B>\n",
    "\n",
    "<B>By this example we will understand How does K-means work </B>\n",
    "\n",
    "<img src=\"images/k-means.png\">\n",
    "<h5 style=\"color:tomato;\"><B> Step1</B></h5>\n",
    "Here we are having a few data points, which we want to cluster. So we would start by picking the number of clusters we want to have.</br>\n",
    "\n",
    "<h5 style=\"color:tomato;\"><B> Step2</B></h5>\n",
    "We have successfully marked the centers of these clusters. Now we will be marking all the points with respective colors on the basis of the distance they have from the centroid.</br>\n",
    "\n",
    "<h5 style=\"color:tomato;\"><B> Step3</B></h5>\n",
    "After marking all the data points, we will now be computing the centroid of this cluster again. We are doing it because initially, we had picked the centroid randomly. Then to remove error, if any, we are doing it.\n",
    "\n",
    "The centroid of the cluster is computed by finding a point within the cluster that would be equidistant from all the data points.</br>\n",
    "\n",
    "<h5 style=\"color:tomato;\"><B> Step4</B></h5>\n",
    "\n",
    "Now since we have computed the centroid again and we know it is not the same as it was before so we would iterate the process again and would find the points nearest to this centroid for each cluster.</br>\n",
    "\n",
    "<h5 style=\"color:tomato;\"><B> Step5</B></h5>\n",
    "Now we have got the result again. One may ask when shall we stop the iteration of this finding the centroid and then placing the data points accordingly? Well, you have to do it till the time when the position of the centroids doesn‚Äôt change.</br>\n",
    "\n",
    "<h5 style=\"color:tomato;\"><B> Step6</B></h5>\n",
    "We marked the two clusters.\n",
    "\n",
    "In this case, it was easy, so we were able to get the results in 2 iterations only.\n",
    "\n",
    "We had also talked about the random initialization that we are putting ourselves into. With this a problem we have is that it can land us up with some really bad clusters which won‚Äôt be of any use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><h4 style=\"color:green;\"><B> K-means Mertrics</B></h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> K-means have 3 distance metrics </B>\n",
    "    <li><B>Euclidean Distance</B></li>\n",
    "    <li><B>Cosine Distance</B></li>\n",
    "    <li><B>Jaccard Similarity</B></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/metricc.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from nltk.cluster.kmeans import KMeansClusterer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.decomposition import PCA      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><h4 style=\"color:green;\"><B> Vectorization</B></h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>TFIDF is another way to convert textual data to numeric form, and is short for Term Frequency-Inverse Document Frequency. The vector value it yields is the product of these two terms; TF and IDF.\n",
    "Let‚Äôs first look at Term Frequency. We have already looked at term frequency with count vectorizer, but this time, we need one more step to calculate the relative frequency. Let‚Äôs say we have two documents in our corpus as below.</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig shape: (13937, 33697)\n",
      "new shape: (13937, 100)\n"
     ]
    }
   ],
   "source": [
    "RUNTIME_MODE = \"Cosine\"\n",
    "SAMPLE_COUNT = 14000\n",
    "MAX_CLUSTER = 25\n",
    "random.seed(1)\n",
    "\n",
    "content = tweets['text'].values # Get the news content to news array\n",
    "\n",
    "stop_words = set(text.ENGLISH_STOP_WORDS)\n",
    "my_stop_words = text.ENGLISH_STOP_WORDS.union([\n",
    " \"also\", \"said\", \"mr\", \"mrs\", \"im\", \"would\", \"could\", \"should\", \"first\", \"like\", \"dont\",\n",
    " \"wont\", \"get\", \"going\", \"ms\", \"one\", \"____\", \"_____\", \"new\", \"news\", \"told\", \"way\",\n",
    " \"year\", \"years\", \"don\", \"day\", \"man\", \"did\", \"just\", \"time\", \"times\", \"make\", \"000\",\n",
    " \"united\", \"state\", \"states\", \"people\", \"ve\", \"white\", \"house\", \"president\",\n",
    " \"government\", \"york\", \"want\", \"know\", \"think\", \"officials\", \"say\", \"breitbart\",\n",
    " \"percent\", \"home\", \"city\", \"case\", \"really\", \"work\", \"according\", \"including\",\n",
    " \"good\", \"campaign\", \"country\", \"long\", \"world\", \"donald\", \"trump\", \"didn\", \"women\",\n",
    " \"called\", \"american\", \"men\", \"later\", \"follow\", \"week\", \"black\", \"little\", \"company\",\n",
    " \"companies\", \"posted\", \"morning\", \"today\", \"evening\", \"com\", \"nytimes\", \"weekend\", \"10\"\n",
    "]\n",
    ")\n",
    "vectorizer = CountVectorizer(stop_words=my_stop_words, binary=False)\n",
    "X_orig = vectorizer.fit_transform(content[0:SAMPLE_COUNT]).toarray()\n",
    "svd = TruncatedSVD(n_components=100, random_state = 0)\n",
    "X = svd.fit_transform(X_orig)\n",
    "print(\"orig shape:\", X_orig.shape)\n",
    "print(\"new shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><h4 style=\"color:green;\"><B> K-means Clustering</B></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\nltk\\cluster\\util.py:131: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - (numpy.dot(u, v) / (sqrt(numpy.dot(u, u)) * sqrt(numpy.dot(v, v))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item count in clusters:\n",
      "Counter({1: 7707, 0: 6230})\n",
      "Item count in clusters:\n",
      "Counter({1: 7473, 0: 3365, 2: 3099})\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names() # Get the array of terms that exists in documents\n",
    "inner_dist = np.zeros(shape=[MAX_CLUSTER - 1])\n",
    "for NUM_CLUSTERS in range(2, MAX_CLUSTER + 1):\n",
    "    kmeans = KMeansClusterer(num_means=NUM_CLUSTERS,\n",
    "    distance=nltk.cluster.util.cosine_distance, repeats=25, avoid_empty_clusters=True)\n",
    "#initial_means=means)\n",
    "    labels = kmeans.cluster(X, assign_clusters=True)\n",
    "    cluster_centers = np.asarray(kmeans.means())\n",
    "    print(\"Item count in clusters:\")\n",
    "    print(Counter(labels))\n",
    "    cluster_means = np.zeros(shape=[NUM_CLUSTERS, len(terms)])\n",
    "    item_counts = np.zeros(shape=[NUM_CLUSTERS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\nltk\\cluster\\util.py:131: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - (numpy.dot(u, v) / (sqrt(numpy.dot(u, u)) * sqrt(numpy.dot(v, v))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item count in clusters:\n",
      "Counter({1: 10359, 0: 3578})\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names() # Get the array of terms that exists in documents\n",
    "NUM_CLUSTERS = 2\n",
    "inner_dist = np.zeros(shape=[MAX_CLUSTER - 1])\n",
    "kmeans = KMeansClusterer(num_means=NUM_CLUSTERS,distance=nltk.cluster.util.cosine_distance, repeats=25, avoid_empty_clusters=True)\n",
    "#initial_means=means)\n",
    "labels = kmeans.cluster(X, assign_clusters=True)\n",
    "cluster_centers = np.asarray(kmeans.means())\n",
    "print(\"Item count in clusters:\")\n",
    "print(Counter(labels))\n",
    "cluster_means = np.zeros(shape=[NUM_CLUSTERS, len(terms)])\n",
    "item_counts = np.zeros(shape=[NUM_CLUSTERS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item count in clusters:\n",
      "Counter({1: 6706, 0: 3214, 3: 2988, 2: 1029})\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names() # Get the array of terms that exists in documents\n",
    "NUM_CLUSTERS = 4\n",
    "inner_dist = np.zeros(shape=[MAX_CLUSTER - 1])\n",
    "kmeans = KMeansClusterer(num_means=NUM_CLUSTERS,distance=nltk.cluster.util.cosine_distance, repeats=25, avoid_empty_clusters=True)\n",
    "#initial_means=means)\n",
    "labels = kmeans.cluster(X, assign_clusters=True)\n",
    "cluster_centers = np.asarray(kmeans.means())\n",
    "print(\"Item count in clusters:\")\n",
    "print(Counter(labels))\n",
    "cluster_means = np.zeros(shape=[NUM_CLUSTERS, len(terms)])\n",
    "item_counts = np.zeros(shape=[NUM_CLUSTERS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = vectorizer.get_feature_names() # Get the array of terms that exists in documents\n",
    "NUM_CLUSTERS = 6\n",
    "inner_dist = np.zeros(shape=[MAX_CLUSTER - 1])\n",
    "kmeans = KMeansClusterer(num_means=NUM_CLUSTERS,distance=nltk.cluster.util.cosine_distance, repeats=25, avoid_empty_clusters=True)\n",
    "#initial_means=means)\n",
    "labels = kmeans.cluster(X, assign_clusters=True)\n",
    "cluster_centers = np.asarray(kmeans.means())\n",
    "print(\"Item count in clusters:\")\n",
    "print(Counter(labels))\n",
    "cluster_means = np.zeros(shape=[NUM_CLUSTERS, len(terms)])\n",
    "item_counts = np.zeros(shape=[NUM_CLUSTERS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><h4 style=\"color:green;\"><B> Top words per Cluster</B></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0 : business  , \n",
      "small  , \n",
      "mind  , \n",
      "yall  , \n",
      "money  , \n",
      "minding  , \n",
      "Cluster 1 : ‚Ñï‚Ñï‚ÑÇ‚Ñï‚Ñö‚Ñ§bigass  , \n",
      "henricovas  , \n",
      "henson  , \n",
      "heptathlon  , \n",
      "herbs  , \n",
      "hercriminal  , \n"
     ]
    }
   ],
   "source": [
    "SAMPLE_COUNT = 13500\n",
    "NUM_CLUSTERS = 2 \n",
    "\n",
    "for ind in range(SAMPLE_COUNT):\n",
    "    cluster_means[labels[ind]] = cluster_means[labels[ind]] + X_orig[ind]\n",
    "    item_counts[labels[ind]] = item_counts[labels[ind]] + 1\n",
    "for ind in range(NUM_CLUSTERS):\n",
    "    cluster_means[ind] = cluster_means[ind] / item_counts[ind]\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = cluster_means.argsort()[:, ::-1]\n",
    "\n",
    "for cls in range(NUM_CLUSTERS):\n",
    "    print(\"Cluster\", cls, ': ', end=''),\n",
    "    for ind in order_centroids[cls, :6]:\n",
    "        print(terms[ind], ' , ', end='')\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_COUNT = 13500\n",
    "NUM_CLUSTERS = 4\n",
    "\n",
    "for ind in range(SAMPLE_COUNT):\n",
    "    cluster_means[labels[ind]] = cluster_means[labels[ind]] + X_orig[ind]\n",
    "    item_counts[labels[ind]] = item_counts[labels[ind]] + 1\n",
    "for ind in range(NUM_CLUSTERS):\n",
    "    cluster_means[ind] = cluster_means[ind] / item_counts[ind]\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = cluster_means.argsort()[:, ::-1]\n",
    "\n",
    "for cls in range(NUM_CLUSTERS):\n",
    "    print(\"Cluster\", cls, ': ', end=''),\n",
    "    for ind in order_centroids[cls, :6]:\n",
    "        print(terms[ind], ' , ', end='')\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> References </B>\n",
    "\n",
    "https://www.datacamp.com/community/tutorials/stemming-lemmatization-python</br>\n",
    "https://datascienceplus.com/twitter-analysis-with-python/</br>\n",
    "https://berkeley-stat159-f17.github.io/stat159-f17/lectures/11-strings/11-nltk..html</br>\n",
    "https://www.xspdf.com/resolution/52940753.html</br>\n",
    "https://medium.com/analytics-vidhya/exploring-twitter-data-using-python-af1287ee65f1</br>\n",
    "https://towardsdatascience.com/kmeans-clustering-for-classification-74b992405d0a\n",
    "https://www.xspdf.com/resolution/55501459.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>For requirements.txt</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting watermark\n",
      "  Downloading watermark-2.1.0-py2.py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: ipython in c:\\users\\user\\anaconda3\\lib\\site-packages (from watermark) (7.16.1)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipython->watermark) (0.4.3)\n",
      "Requirement already satisfied: backcall in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipython->watermark) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipython->watermark) (3.0.5)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipython->watermark) (4.4.2)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipython->watermark) (0.17.1)\n",
      "Requirement already satisfied: pygments in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipython->watermark) (2.6.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipython->watermark) (4.3.3)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipython->watermark) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipython->watermark) (49.2.0.post20200714)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->watermark) (0.2.5)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython->watermark) (0.7.0)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from traitlets>=4.2->ipython->watermark) (1.15.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\user\\anaconda3\\lib\\site-packages (from traitlets>=4.2->ipython->watermark) (0.2.0)\n",
      "Installing collected packages: watermark\n",
      "Successfully installed watermark-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install watermark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "::\n",
       "\n",
       "  %watermark [-a AUTHOR] [-d] [-n] [-t] [-i] [-z] [-u] [-c CUSTOM_TIME] [-v] [-p PACKAGES] [-h] [-m] [-g] [-r]\n",
       "                 [-b] [-w] [-iv]\n",
       "\n",
       "IPython magic function to print date/time stamps\n",
       "and various system information.\n",
       "\n",
       "optional arguments:\n",
       "  -a AUTHOR, --author AUTHOR\n",
       "                        prints author name\n",
       "  -d, --date            prints current date as YYYY-mm-dd\n",
       "  -n, --datename        prints date with abbrv. day and month names\n",
       "  -t, --time            prints current time as HH-MM-SS\n",
       "  -i, --iso8601         prints the combined date and time including the time zone in the ISO 8601 standard with UTC\n",
       "                        offset\n",
       "  -z, --timezone        appends the local time zone\n",
       "  -u, --updated         appends a string \"Last updated: \"\n",
       "  -c CUSTOM_TIME, --custom_time CUSTOM_TIME\n",
       "                        prints a valid strftime() string\n",
       "  -v, --python          prints Python and IPython version\n",
       "  -p PACKAGES, --packages PACKAGES\n",
       "                        prints versions of specified Python modules and packages\n",
       "  -h, --hostname        prints the host name\n",
       "  -m, --machine         prints system and machine info\n",
       "  -g, --githash         prints current Git commit hash\n",
       "  -r, --gitrepo         prints current Git remote address\n",
       "  -b, --gitbranch       prints current Git branch\n",
       "  -w, --watermark       prints the current version of watermark\n",
       "  -iv, --iversions      prints the name/version of all imported modules\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\user\\anaconda3\\lib\\site-packages\\watermark\\watermark.py\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%watermark?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.8.3\n",
      "IPython version      : 7.16.1\n",
      "\n",
      "pandas : 1.0.5\n",
      "numpy  : 1.18.5\n",
      "plt    : not installed\n",
      "kmeans : not installed\n",
      "counter: not installed\n",
      "\n",
      "Compiler    : MSC v.1916 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 142 Stepping 12, GenuineIntel\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p  pandas,numpy,plt,kmeans,counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.8.3\n",
      "IPython version      : 7.16.1\n",
      "\n",
      "TfidfVectorizer  : not installed\n",
      "CountVectorizer  : not installed\n",
      "text             : not installed\n",
      "KMeansClusterer  : not installed\n",
      "cosine_similarity: not installed\n",
      "TruncatedSVD     : not installed\n",
      "datetime         : unknown\n",
      "nltk             : 3.5\n",
      "PCA              : not installed\n",
      "pd               : not installed\n",
      "np               : not installed\n",
      "\n",
      "Compiler    : MSC v.1916 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 142 Stepping 12, GenuineIntel\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p TfidfVectorizer,CountVectorizer,text,KMeansClusterer,cosine_similarity,TruncatedSVD,datetime,nltk,PCA,pd,np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.8.3\n",
      "IPython version      : 7.16.1\n",
      "\n",
      "display: not installed\n",
      "seaborn: 0.10.1\n",
      "\n",
      "Compiler    : MSC v.1916 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 142 Stepping 12, GenuineIntel\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p  display,seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.8.3\n",
      "IPython version      : 7.16.1\n",
      "\n",
      "tweepy: 3.9.0\n",
      "\n",
      "Compiler    : MSC v.1916 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 142 Stepping 12, GenuineIntel\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p tweepy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
